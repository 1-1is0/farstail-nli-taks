{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, BertConfig\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "def rtl_print(outputs, font_size=\"15px\", n_to_br=False):\n",
    "    outputs = outputs if isinstance(outputs, list) else [outputs] \n",
    "    if n_to_br:\n",
    "        outputs = [output.replace('\\n', '') for output in outputs]\n",
    "        \n",
    "    outputs = [f'{output}' for output in outputs]\n",
    "    display.display(display.HTML(' '.join(outputs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/FarsTail/data/Train-word.csv', sep='\\t')\n",
    "val_df = pd.read_csv('./data/FarsTail/data/Val-word.csv', sep='\\t')\n",
    "test_df = pd.read_csv('./data/FarsTail/data/Test-word.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...</td>\n",
       "      <td>نخستین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...</td>\n",
       "      <td>کانون های جغرافیایی مصر، اندلس و شام، نخستین ر...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...</td>\n",
       "      <td>سیسیل بعد از اسپانیا بزرگ ترین کانونی بود که ه...</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ویژگی های هنر عصر اموی: ۱- تلفیقی بودن ۲- بازن...</td>\n",
       "      <td>نقاشی های تزئینی و تندیس های بی‌کیفیت، یکی از ...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ویژگی های هنر عصر اموی: ۱- تلفیقی بودن ۲- بازن...</td>\n",
       "      <td>با کیفیت بودن تندیس های دوره اموی، یکی از ویژگ...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise   \n",
       "0  اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...  \\\n",
       "1  اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...   \n",
       "2  اولین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی ...   \n",
       "3  ویژگی های هنر عصر اموی: ۱- تلفیقی بودن ۲- بازن...   \n",
       "4  ویژگی های هنر عصر اموی: ۱- تلفیقی بودن ۲- بازن...   \n",
       "\n",
       "                                          hypothesis label  \n",
       "0  نخستین انتقال و نفوذ طبیعی فرهنگ و تمدن اسلامی...     e  \n",
       "1  کانون های جغرافیایی مصر، اندلس و شام، نخستین ر...     c  \n",
       "2  سیسیل بعد از اسپانیا بزرگ ترین کانونی بود که ه...     n  \n",
       "3  نقاشی های تزئینی و تندیس های بی‌کیفیت، یکی از ...     e  \n",
       "4  با کیفیت بودن تندیس های دوره اموی، یکی از ویژگ...     c  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label_id'] = label_encoder.fit_transform(train_df['label'])\n",
    "val_df['label_id'] = label_encoder.transform(val_df['label'])\n",
    "test_df['label_id'] = label_encoder.transform(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = 50\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # x = torch.tensor(row['text'], dtype=torch.float32)\n",
    "        premise = row[\"premise\"]\n",
    "        hypothesis = row[\"hypothesis\"]\n",
    "        label = row[\"label\"]\n",
    "        label_id = row[\"label_id\"]\n",
    "        # text = f\"{self.tokenizer.cls_token} {premise} {self.tokenizer.sep_token} {hypothesis} {self.tokenizer.sep_token}\"\n",
    "        # Tokenize inputs\n",
    "        encoded_inputs = self.tokenizer.encode_plus(\n",
    "            premise,\n",
    "            hypothesis,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = encoded_inputs[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoded_inputs[\"attention_mask\"].squeeze()\n",
    "        token_type_id = encoded_inputs[\"token_type_ids\"].squeeze()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"token_type_ids\": token_type_id,\n",
    "            \"label\": label,\n",
    "            \"label_id\": torch.tensor(label_id, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attention mask  \n",
    "https://huggingface.co/transformers/v3.2.0/glossary.html#attention-mask  \n",
    "token type id  \n",
    "https://huggingface.co/transformers/v3.2.0/glossary.html#token-type-ids  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# config = AutoConfig.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "model = AutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "# model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_auto_class',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_create_repo',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_files_timestamps',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_prune_heads',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'adjust_logits_during_generation',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'embeddings',\n",
       " 'enable_input_require_grads',\n",
       " 'encoder',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_loaded_in_8bit',\n",
       " 'is_parallelizable',\n",
       " 'load_state_dict',\n",
       " 'load_tf_weights',\n",
       " 'main_input_name',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'pooler',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "train_dataset = Dataset(train_df, tokenizer)\n",
    "val_dataset = Dataset(val_df, tokenizer)\n",
    "test_dataset = Dataset(test_df, tokenizer)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = cpu_count() - 2\n",
    "pin_memory = True if device == \"cuda\" else False\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from transformers import *\n",
    "# from utils.utils import build_batch\n",
    "\n",
    "\n",
    "class BertNLIModel(nn.Module):\n",
    "    \"\"\"Performs prediction, given the input of BERT embeddings.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path=None,\n",
    "        label_num=3,\n",
    "        reinit_num=0,\n",
    "        freeze_layers=True,\n",
    "    ):\n",
    "        super(BertNLIModel, self).__init__()\n",
    "        # self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            \"HooshvareLab/bert-base-parsbert-uncased\"\n",
    "        )\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"HooshvareLab/bert-base-parsbert-uncased\"\n",
    "        )\n",
    "        self.bert = AutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "\n",
    "        self.new_config = BertConfig(\n",
    "            attention_probs_dropout_prob=self.config.attention_probs_dropout_prob,\n",
    "            hidden_dropout_prob=self.config.hidden_dropout_prob,\n",
    "            hidden_size=self.config.hidden_size,\n",
    "            initializer_range=self.config.initializer_range,\n",
    "            intermediate_size=self.config.intermediate_size,\n",
    "            layer_norm_eps=self.config.layer_norm_eps,\n",
    "            max_position_embeddings=self.config.max_position_embeddings,\n",
    "            num_attention_heads=int(self.config.num_attention_heads / 2),  # Reduce the number of attention heads by half\n",
    "            num_hidden_layers=int(self.config.num_hidden_layers / 2),  # Reduce the number of hidden layers by half\n",
    "            num_labels=self.config.num_labels,\n",
    "            output_attentions=self.config.output_attentions,\n",
    "            output_hidden_states=self.config.output_hidden_states,\n",
    "            pad_token_id=self.config.pad_token_id,\n",
    "            type_vocab_size=self.config.type_vocab_size,\n",
    "            vocab_size=self.config.vocab_size\n",
    "        )\n",
    "    \n",
    "\n",
    "        self.num_hidden_layers = self.config.num_hidden_layers\n",
    "        self.vdim = self.config.hidden_size\n",
    "\n",
    "        self.nli_head1 = nn.Linear(self.vdim, 250)\n",
    "        self.nli_head2 = nn.Linear(250, label_num)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "        self.reinit(layer_num=reinit_num, freeze=freeze_layers)\n",
    "\n",
    "    def reinit(self, layer_num, freeze):\n",
    "        \"\"\"Reinitialise parameters of last N layers and freeze all others\"\"\"\n",
    "        if freeze:\n",
    "            for _, pp in self.bert.named_parameters():\n",
    "                pp.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        cls_vecs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_attentions=self.new_config.output_attentions,\n",
    "            output_hidden_states=self.new_config.output_hidden_states,\n",
    "        )[1]\n",
    "\n",
    "        logits = self.nli_head1(cls_vecs)\n",
    "        logits = self.nli_head2(logits)\n",
    "        probs = self.sm(logits)\n",
    "\n",
    "        torch.cuda.empty_cache()  # releases all unoccupied cached memory\n",
    "\n",
    "        return logits, probs\n",
    "\n",
    "    def _get_name(self):\n",
    "        return f\"{super()._get_name()}-head-{self.new_config.num_attention_heads}\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"BertNLIModel-Encoder-{self.new_config.num_attention_heads}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BertNLIModel-Encoder-{self.new_config.num_attention_heads}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertNLIModel(label_num=3)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=2e-5,eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))\n",
    "\n",
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "token_type_ids = data['token_type_ids'].to(device)\n",
    "label_id = data['label_id'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/state-BertNLIModel-head-6-optimizer-AdamW-loss-CrossEntropyLoss.pth exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37s] Epoch 26 loss : 0.97526053 acc: 51.23 val: 0.98563907 acc: 49.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### BETTER NET STATE ###\n",
      "[50s] Epoch 27 loss : 0.97459611 acc: 51.57 val: 0.96639781 acc: 51.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92s] Epoch 28 loss : 0.97178357 acc: 51.84 val: 0.96847961 acc: 50.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 36/49 [00:36<00:13,  1.02s/it, epoch=29, phase=val, loss=7.0967]    "
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "from easydict import EasyDict\n",
    "\n",
    "dataset = EasyDict(\n",
    "    {\n",
    "        \"train\": train_dataset,\n",
    "        \"val\": test_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    ")\n",
    "data_loader = EasyDict(\n",
    "    {\n",
    "        \"train\": train_loader,\n",
    "        \"val\": test_loader,\n",
    "        \"test\": test_loader,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "start = train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=data_loader,\n",
    "    dataset=dataset,\n",
    "    device=device,\n",
    "    epochs=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.983513378367132\n",
      "accuracy 0.5017310495626822\n",
      "precision 0.5017310495626822\n",
      "recall 0.5017310495626822\n",
      "f1 0.5017310495626822\n",
      "[[253 211  46]\n",
      " [162 328  29]\n",
      " [203 128 204]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tools import evaluate_loader, show_cm\n",
    "\n",
    "with torch.no_grad():\n",
    "    metrics = evaluate_loader(test_loader, model, criterion, device)\n",
    "    cm = show_cm(model, test_loader, device)\n",
    "\n",
    "for key, val in metrics.items():\n",
    "    print(key, val)\n",
    "\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
